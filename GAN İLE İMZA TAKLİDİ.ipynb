import tensorflow as tf
from tensorflow.keras.layers import Input, Reshape, Dropout, Dense 
from tensorflow.keras.layers import Flatten, BatchNormalization
from tensorflow.keras.layers import Activation, ZeroPadding2D
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.layers import UpSampling2D, Conv2D
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.optimizers import Adam
import numpy as np
from PIL import Image
from tqdm import tqdm
import os 
import matplotlib.pyplot as plt
import time


RESIM_BOYUTU = 96 # giriş boyutu
image_shape = (96,96,3) # discriminator girişi

# Kaydetme işlemindeki boyut ayarlama parametreleri
SATIR = 4 
SUTUN = 7
KENAR = 16

GURULTU_BOYUTU = 100  # generator giriş gürültü sayısı
EPOCHS = 200 # kaç adet fotoğraf üretileceği
learning_rate = 0.007
VERI_YOLU = '/content/drive/My Drive/TestDatamız/test16' # drive veri yolu
time.sleep(2)


training_binary_path = os.path.join(VERI_YOLU) #  veri seti için yol oluşturma

print("Dosya Yolu Aranıyor {}: \n".format(VERI_YOLU))

if not os.path.isfile(training_binary_path): # eğitim dosyalarını yükleme
  print("Eğitim dosyaları yükleniyor...")
  time.sleep(2)


  training_data = [] 
  signature_path = os.path.join(VERI_YOLU) # eğitim seti
  for filename in tqdm(os.listdir(signature_path)):
      path = os.path.join(signature_path,filename)
      image = Image.open(path).resize((RESIM_BOYUTU,RESIM_BOYUTU),Image.ANTIALIAS) # eğitim setini yeniden boyutlandırıp training_dataya'ya ekleme
      training_data.append(np.asarray(image))
  training_data = np.reshape(training_data,(-1,RESIM_BOYUTU,RESIM_BOYUTU,KANAL_SAYISI)) # generator girişi için veri girişini 3 boyutlu hale getirme
  training_data = training_data.astype(np.float32) # verisetini float değerlere taşıma işlemi
  training_data = training_data / 127.5 - 1. # verisetini -1 ile 1 arasına sıkıştırma
  print("\nEğitim dosyaları kaydedildi\n")
  np.save(training_binary_path,training_data) # dosyayı .npy formatında kaydetme.

else:
  print("Önceki eğitim dosyası bilgileri yükleniyor..")
  training_data = np.load(training_binary_path) # kod daha önceden çalıştırılmışsa .npy dosyasını belirtilen yoldan yükleme işlemi.

train_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(60000).batch(8) # giriş verisetinin karıştırılması ve eğitim için uygun boyutlara getirilmesi

#generator modeli // başlangıç 1 // son katmanda 96x96x3 //

def build_generator(gurultu = 100, kanal = 3, activation='relu'):
    model = Sequential()
    model.add(Dense(4*4*256,activation="relu",input_dim=gurultu))
    model.add(Reshape((4,4,256)))

    model.add(UpSampling2D())
    model.add(Conv2D(256,(3, 3),padding="same")) # 8x8x256
    model.add(BatchNormalization())
    model.add(Activation(activation))

    model.add(UpSampling2D())
    model.add(Conv2D(256,(3, 3),padding="same")) # 16x16x256
    model.add(BatchNormalization())
    model.add(Activation(activation))
   
    model.add(UpSampling2D())
    model.add(Conv2D(128,(3, 3),padding="same")) # 32x32x128
    model.add(BatchNormalization())
    model.add(Activation(activation))

    model.add(UpSampling2D(size=(3,3)))
    model.add(Conv2D(128,(3, 3),padding="same")) # 96x96x128
    model.add(BatchNormalization())
    model.add(Activation(activation))

    # Final CNN katmanı
    model.add(Conv2D(3,(3, 3),padding="same")) # 96x96x3
    model.add(Activation("tanh"))

    print(model.summary())
    return model

#disriminator modeli // başlangıç 96x96x3 // son katmanda 1 //

def build_discriminator(image_shape = (96,96,3),  nb_filter=32):
    model = Sequential()
    model.add(Conv2D(nb_filter, (3, 3), strides=2, input_shape=image_shape, padding="same"))
    model.add(LeakyReLU(alpha=0.2))

    model.add(Dropout(0.25))
    model.add(Conv2D(2*nb_filter, (3, 3), strides=2, padding="same"))
    model.add(ZeroPadding2D(padding=((0,1),(0,1))))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))

    model.add(Dropout(0.25))
    model.add(Conv2D(4*nb_filter, (3, 3), strides=2, padding="same"))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))

    model.add(Dropout(0.25))
    model.add(Conv2D(8*nb_filter, (3, 3), strides=1, padding="same"))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))

    model.add(Dropout(0.25))
    model.add(Conv2D(16*nb_filter, (3, 3), strides=1, padding="same"))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))

    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))

    print(model.summary())
    return model

generator = build_generator(100, 3,'relu') 
discriminator = build_discriminator(image_shape,32)


gurultu = tf.random.normal([1, GURULTU_BOYUTU])
generated_images = generator(gurultu, training=False) 

cross_entropy = tf.keras.losses.BinaryCrossentropy() # ikili etiketlerde kullanılan kayıp fonksiyonu


g_optimize = tf.keras.optimizers.Adam(learning_rate,beta_1 = 0.5) # optimizasyon işlemi
d_optimize = tf.keras.optimizers.Adam(learning_rate,beta_1 = 0.5)

def train_process(images): # eğitim aşaması

  seed = tf.random.normal([8, GURULTU_BOYUTU])

  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: # loss oranlarını hesaplama ve model eğitim kısmı
    generated_images = generator(seed, training=True) # generator eğitim 

    #discriminator eğitim
    gercek_gorsel = discriminator(images, training=True)
    sahte_gorsel = discriminator(generated_images, training=True)

    #loss oranları
    gen_kayıp = generator_loss(sahte_gorsel)
    disc_kayıp = discriminator_loss(gercek_gorsel, sahte_gorsel)
    

    gradients_of_generator = gen_tape.gradient(gen_kayıp, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_kayıp, discriminator.trainable_variables)

    g_optimize.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) 
    d_optimize.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))
  return gen_kayıp,disc_kayıp

def train(dataset, epochs): # verilerin eğitime yollandığı kısım

  f_seed = np.random.normal(0, 1, (SATIR * SUTUN,GURULTU_BOYUTU))

  for epoch in range(epochs):

    gen_kayıp_listesi = []
    disc_kayıp_listesi = []

    for image_batch in dataset: # output üretimi ve loss oranlarını listeye aktarma
      t = train_step(image_batch)
      gen_kayıp_listesi.append(t[0])
      disc_kayıp_listesi.append(t[1])

    g_kayıp = sum(gen_kayıp_listesi) / len(gen_kayıp_listesi)
    d_kayıp = sum(disc_kayıp_listesi) / len(disc_kayıp_listesi)

    print (f'Epoch {epoch+1}, generator kaybı={g_kayıp},discriminator kaybı={d_kayıp}')
    goruntu_kaydet(epoch,f_seed) # görüntileri kaydetme


#discriminator loss hesaplama
def discriminator_loss(gercek_gorsel, sahte_gorsel):
    gercek_kayıp = cross_entropy(tf.ones_like(gercek_gorsel), gercek_gorsel)
    sahte_kayıp = cross_entropy(tf.zeros_like( sahte_gorsel),  sahte_gorsel)
    toplam_kayıp = gercek_kayıp + sahte_kayıp
    return toplam_kayıp

#generator loss hesaplama
def generator_loss(sahte_gorsel):
    return cross_entropy(tf.ones_like(sahte_gorsel), sahte_gorsel)

#görüntü kaydetme
def goruntu_kaydet(cnt,gurultu):

  image_array = np.full(( KENAR + (SATIR * (RESIM_BOYUTU+KENAR)), KENAR + (SUTUN* (RESIM_BOYUTU+KENAR)), 3), 255, dtype=np.uint8) # görüntü boyutu
  
  generated_images = generator.predict(gurultu)
  generated_images = 0.5 * generated_images + 0.5

  image_count = 0
  for row in range(SATIR): # resmi boyutlandırma
      for col in range(SUTUN):
        r = row * (RESIM_BOYUTU+16) + KENAR
        c = col * (RESIM_BOYUTU+16) + KENAR
        image_array[r:r+RESIM_BOYUTU,c:c+RESIM_BOYUTU] = generated_images[image_count] * 255
        image_count += 1

  output_path = os.path.join(VERI_YOLU,'output') # output klasörü oluşturma
  if not os.path.exists(output_path):
    os.makedirs(output_path)
  
  filename = os.path.join(output_path,f"train-{cnt}.png") 
  im = Image.fromarray(image_array)
  im.save(filename) # görselleri kaydetme

train(train_dataset, EPOCHS)


